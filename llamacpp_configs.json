{
    "model_directory":"./dummy_llm_files",
    "default_model":"mixtral-8x7b-instruct-v0.1.Q4_K_M",
    "models":
    {
        "mixtral-8x7b-instruct-v0.1.Q4_K_M":
        {
            "name":"mixtral-8x7b-instruct-v0.1.Q4_K_M",
            "family":"mixtral",
            "specialization":"instruct",
            "parameters":
            {
                "n_ctx":3096,
                "n_threads":12,
                "n_gpu_layers":16
            }
        },
        "mixtral-8x7b-instruct-v0.1.Q5_K_M":
        {
            "name":"mixtral-8x7b-instruct-v0.1.Q5_K_M",
            "family":"mixtral",
            "specialization":"instruct",
            "parameters":
            {
                "n_ctx":3096,
                "n_threads":12,
                "n_gpu_layers":16
            }
        },
        "Meta-Llama-3-8B-Instruct.Q5_K_M":
        {
            "name":"Meta-Llama-3-8B-Instruct.Q5_K_M",
            "family":"llama",
            "specialization":"instruct",
            "parameters":
            {
                "n_ctx":3096,
                "n_threads":12,
                "n_gpu_layers":32
            }
        },
        "Meta-Llama-3-8B-Instruct.Original":
        {
            "name":"Meta-Llama-3-8B-Instruct.Original",
            "family":"llama",
            "specialization":"instruct",
            "parameters":
            {
                "n_ctx":3096,
                "n_threads":12,
                "n_gpu_layers":16
            }
        },
        "Meta-Llama-3-70B-Instruct.Q5_K_M":{
            "name":"Meta-Llama-3-70B-Instruct.Q5_K_M",
            "family":"llama",
            "specialization":"instruct",
            "parameters":
            {
                "n_ctx":3096,
                "n_threads":18,
                "n_gpu_layers":30
            }
        }
    }
}